{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    \"5% of younger population , these people experienced side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    \"5% of older people who did not have side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "\n",
    "for i in range(1000):\n",
    "    \"95% of younger population , these people did not experience  side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    \"95% of older people who experienced side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to numpy arrays and shuffling the data to remove any order that was imposed while creating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels , train_samples = shuffle(train_labels,train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, ..., 0, 1, 1]), array([55, 34, 56, ..., 23, 96, 98]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels,train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling down training which is in range 13-100 to 0-1 \n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([55, 34, 56, ..., 23, 96, 98]),\n",
       " '--------------------------',\n",
       " array([[0.48275862],\n",
       "        [0.24137931],\n",
       "        [0.49425287],\n",
       "        ...,\n",
       "        [0.11494253],\n",
       "        [0.95402299],\n",
       "        [0.97701149]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_samples,\"--------------------------\",scaled_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz questions:\n",
    "\n",
    "To train any neural network in a supervised learning task, we first need _______________.      \n",
    "a data set of samples and labels\n",
    "\n",
    "Samples are also commonly referred to as _______________.    \n",
    "input data\n",
    "\n",
    "Labels are also commonly referred to as _______________.     \n",
    "target data\n",
    "\n",
    "How will we pass training data to a tf.keras Sequential model?       \n",
    "Via the Sequential.fit() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape = (1,), activation = 'relu'),\n",
    "    Dense(32, activation= 'relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fe735d272d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fe73d6e3c90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fe73d708150>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr= 0.001), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6323 - val_loss: 0.4477 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8974 - val_loss: 0.2434 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.9360 - val_loss: 0.1904 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.9386 - val_loss: 0.1733 - val_accuracy: 0.9714\n",
      "Epoch 5/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.9392 - val_loss: 0.1639 - val_accuracy: 0.9571\n",
      "Epoch 6/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.9423 - val_loss: 0.1580 - val_accuracy: 0.9714\n",
      "Epoch 7/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9376 - val_loss: 0.1603 - val_accuracy: 0.9619\n",
      "Epoch 8/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.9423 - val_loss: 0.1565 - val_accuracy: 0.9714\n",
      "Epoch 9/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.9423 - val_loss: 0.1471 - val_accuracy: 0.9714\n",
      "Epoch 10/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9423 - val_loss: 0.1442 - val_accuracy: 0.9714\n",
      "Epoch 11/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9439 - val_loss: 0.1462 - val_accuracy: 0.9714\n",
      "Epoch 12/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9429 - val_loss: 0.1443 - val_accuracy: 0.9714\n",
      "Epoch 13/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9439 - val_loss: 0.1455 - val_accuracy: 0.9714\n",
      "Epoch 14/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.9439 - val_loss: 0.1424 - val_accuracy: 0.9714\n",
      "Epoch 15/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.9407 - val_loss: 0.1440 - val_accuracy: 0.9714\n",
      "Epoch 16/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9450 - val_loss: 0.1396 - val_accuracy: 0.9714\n",
      "Epoch 17/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9376 - val_loss: 0.1459 - val_accuracy: 0.9619\n",
      "Epoch 18/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9439 - val_loss: 0.1422 - val_accuracy: 0.9714\n",
      "Epoch 19/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9413 - val_loss: 0.1387 - val_accuracy: 0.9571\n",
      "Epoch 20/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9434 - val_loss: 0.1386 - val_accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe73d7da4d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=True, validation_split= 0.1)\n",
    "# shuffle = True by default , if validation data is added , it will not be shuffled the same data will be used always\n",
    "# for each batch we should have random data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test data similar to how train data was generated , in real world we have real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    \"5% of younger population , these people experienced side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    \"5% of older people who did not have side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    \"95% of younger population , these people did not experience  side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    \"95% of older people who experienced side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicitng using the previously built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9618372 , 0.03816288],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.96177   , 0.03822998],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9620377 , 0.03796225],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.6307786 , 0.3692214 ],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.9626991 , 0.03730081],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.96223736, 0.03776266],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.96341395, 0.03658603],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.02234189, 0.97765815],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9443925 , 0.05560752],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.96328497, 0.036715  ],\n",
       "       [0.00956456, 0.9904355 ],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.96177   , 0.03822998],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9630907 , 0.03690929],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.9629606 , 0.03703936],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.69360745, 0.3063925 ],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.9627647 , 0.03723529],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.96223736, 0.03776266],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9627647 , 0.03723529],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.96243596, 0.03756407],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.01809175, 0.98190826],\n",
       "       [0.91693425, 0.08306578],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9621043 , 0.03789561],\n",
       "       [0.09353005, 0.90646994],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9630907 , 0.03690929],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.00956456, 0.9904355 ],\n",
       "       [0.9637983 , 0.03620172],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.00956456, 0.9904355 ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9635425 , 0.0364575 ],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.7989912 , 0.20100878],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.04630977, 0.95369023],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.9626991 , 0.03730081],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.94003433, 0.05996564],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.9621709 , 0.03782908],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.6307786 , 0.3692214 ],\n",
       "       [0.01064032, 0.98935974],\n",
       "       [0.94003433, 0.05996564],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9637983 , 0.03620172],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.9520757 , 0.04792422],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9443925 , 0.05560752],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9621709 , 0.03782908],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.96223736, 0.03776266],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.02234189, 0.97765815],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.94003433, 0.05996564],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9621043 , 0.03789561],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.961971  , 0.03802902],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.69360745, 0.3063925 ],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.9635425 , 0.0364575 ],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.96341395, 0.03658603],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.96328497, 0.036715  ],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.02234189, 0.97765815],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.04630977, 0.95369023],\n",
       "       [0.96328497, 0.036715  ],\n",
       "       [0.01809175, 0.98190826],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9629606 , 0.03703936],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.9621709 , 0.03782908],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9618372 , 0.03816288],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9637983 , 0.03620172],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9547874 , 0.04521263],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9626991 , 0.03730081],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.961971  , 0.03802902],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.09353005, 0.90646994],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9627647 , 0.03723529],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9443925 , 0.05560752],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9520757 , 0.04792422],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.7989912 , 0.20100878],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.7989912 , 0.20100878],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9635425 , 0.0364575 ],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9629606 , 0.03703936],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9547874 , 0.04521263],\n",
       "       [0.01627501, 0.983725  ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404761904761905"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(rounded_predictions , test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix to visually see how the model is predicting on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlcondab0e91abca1e444e6ba4cae782abe292d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
