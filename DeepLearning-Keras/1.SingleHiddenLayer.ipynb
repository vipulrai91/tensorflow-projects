{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    \"5% of younger population , these people experienced side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    \"5% of older people who did not have side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "\n",
    "for i in range(1000):\n",
    "    \"95% of younger population , these people did not experience  side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    \"95% of older people who experienced side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to numpy arrays and shuffling the data to remove any order that was imposed while creating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels , train_samples = shuffle(train_labels,train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, ..., 0, 1, 1]), array([55, 34, 56, ..., 23, 96, 98]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels,train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling down training which is in range 13-100 to 0-1 \n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([55, 34, 56, ..., 23, 96, 98]),\n",
       " '--------------------------',\n",
       " array([[0.48275862],\n",
       "        [0.24137931],\n",
       "        [0.49425287],\n",
       "        ...,\n",
       "        [0.11494253],\n",
       "        [0.95402299],\n",
       "        [0.97701149]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_samples,\"--------------------------\",scaled_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz questions:\n",
    "\n",
    "To train any neural network in a supervised learning task, we first need _______________.      \n",
    "a data set of samples and labels\n",
    "\n",
    "Samples are also commonly referred to as _______________.    \n",
    "input data\n",
    "\n",
    "Labels are also commonly referred to as _______________.     \n",
    "target data\n",
    "\n",
    "How will we pass training data to a tf.keras Sequential model?       \n",
    "Via the Sequential.fit() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape = (1,), activation = 'relu'),\n",
    "    Dense(32, activation= 'relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fe735d272d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fe73d6e3c90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fe73d708150>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr= 0.001), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6323 - val_loss: 0.4477 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8974 - val_loss: 0.2434 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.9360 - val_loss: 0.1904 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.9386 - val_loss: 0.1733 - val_accuracy: 0.9714\n",
      "Epoch 5/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.9392 - val_loss: 0.1639 - val_accuracy: 0.9571\n",
      "Epoch 6/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.9423 - val_loss: 0.1580 - val_accuracy: 0.9714\n",
      "Epoch 7/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9376 - val_loss: 0.1603 - val_accuracy: 0.9619\n",
      "Epoch 8/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.9423 - val_loss: 0.1565 - val_accuracy: 0.9714\n",
      "Epoch 9/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.9423 - val_loss: 0.1471 - val_accuracy: 0.9714\n",
      "Epoch 10/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9423 - val_loss: 0.1442 - val_accuracy: 0.9714\n",
      "Epoch 11/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9439 - val_loss: 0.1462 - val_accuracy: 0.9714\n",
      "Epoch 12/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9429 - val_loss: 0.1443 - val_accuracy: 0.9714\n",
      "Epoch 13/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9439 - val_loss: 0.1455 - val_accuracy: 0.9714\n",
      "Epoch 14/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.9439 - val_loss: 0.1424 - val_accuracy: 0.9714\n",
      "Epoch 15/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.9407 - val_loss: 0.1440 - val_accuracy: 0.9714\n",
      "Epoch 16/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9450 - val_loss: 0.1396 - val_accuracy: 0.9714\n",
      "Epoch 17/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9376 - val_loss: 0.1459 - val_accuracy: 0.9619\n",
      "Epoch 18/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9439 - val_loss: 0.1422 - val_accuracy: 0.9714\n",
      "Epoch 19/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9413 - val_loss: 0.1387 - val_accuracy: 0.9571\n",
      "Epoch 20/20\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9434 - val_loss: 0.1386 - val_accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe73d7da4d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=True, validation_split= 0.1)\n",
    "# shuffle = True by default , if validation data is added , it will not be shuffled the same data will be used always\n",
    "# for each batch we should have random data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test data similar to how train data was generated , in real world we have real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    \"5% of younger population , these people experienced side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    \"5% of older people who did not have side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    \"95% of younger population , these people did not experience  side effect \"\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    \"95% of older people who experienced side effect\"\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicitng using the previously built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9618372 , 0.03816288],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.96177   , 0.03822998],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9620377 , 0.03796225],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.6307786 , 0.3692214 ],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.9626991 , 0.03730081],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.96223736, 0.03776266],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.96341395, 0.03658603],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.02234189, 0.97765815],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9443925 , 0.05560752],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.96328497, 0.036715  ],\n",
       "       [0.00956456, 0.9904355 ],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.96177   , 0.03822998],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9630907 , 0.03690929],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.9629606 , 0.03703936],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.69360745, 0.3063925 ],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.9627647 , 0.03723529],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.96223736, 0.03776266],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9627647 , 0.03723529],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.96243596, 0.03756407],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.01809175, 0.98190826],\n",
       "       [0.91693425, 0.08306578],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9621043 , 0.03789561],\n",
       "       [0.09353005, 0.90646994],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9630907 , 0.03690929],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.00956456, 0.9904355 ],\n",
       "       [0.9637983 , 0.03620172],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.00956456, 0.9904355 ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9635425 , 0.0364575 ],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.7989912 , 0.20100878],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.04630977, 0.95369023],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.9626991 , 0.03730081],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.94003433, 0.05996564],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.08479214, 0.9152078 ],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.96315557, 0.03684441],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.9621709 , 0.03782908],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.9249724 , 0.07502764],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.9633495 , 0.03665047],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.6307786 , 0.3692214 ],\n",
       "       [0.01064032, 0.98935974],\n",
       "       [0.94003433, 0.05996564],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9637983 , 0.03620172],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.9520757 , 0.04792422],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9443925 , 0.05560752],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9621709 , 0.03782908],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.96223736, 0.03776266],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.02234189, 0.97765815],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.03396055, 0.9660394 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.00859661, 0.9914034 ],\n",
       "       [0.94003433, 0.05996564],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9621043 , 0.03789561],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.961971  , 0.03802902],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.69360745, 0.3063925 ],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.06950652, 0.9304935 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.07680144, 0.9231986 ],\n",
       "       [0.9635425 , 0.0364575 ],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.96341395, 0.03658603],\n",
       "       [0.05130434, 0.94869566],\n",
       "       [0.49314964, 0.5068503 ],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.96328497, 0.036715  ],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.02234189, 0.97765815],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.04630977, 0.95369023],\n",
       "       [0.96328497, 0.036715  ],\n",
       "       [0.01809175, 0.98190826],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9629606 , 0.03703936],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.12474363, 0.8752564 ],\n",
       "       [0.9621709 , 0.03782908],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.9625678 , 0.03743222],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.8404369 , 0.15956311],\n",
       "       [0.014638  , 0.98536193],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9618372 , 0.03816288],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9637983 , 0.03620172],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.9573524 , 0.04264757],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.03767585, 0.9623242 ],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9636066 , 0.03639338],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9636706 , 0.03632939],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.02481876, 0.97518116],\n",
       "       [0.9547874 , 0.04521263],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.01316344, 0.98683655],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.19745557, 0.80254436],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9626991 , 0.03730081],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.91693425, 0.08306579],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.961971  , 0.03802902],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.93535805, 0.06464197],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.13698226, 0.8630177 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.2401883 , 0.75981164],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.93034405, 0.06965593],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.2948707 , 0.70512927],\n",
       "       [0.9619041 , 0.03809589],\n",
       "       [0.05680545, 0.9431945 ],\n",
       "       [0.962502  , 0.03749808],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.42338738, 0.5766126 ],\n",
       "       [0.96322036, 0.03677967],\n",
       "       [0.11345463, 0.8865454 ],\n",
       "       [0.9628302 , 0.03716986],\n",
       "       [0.01627501, 0.983725  ],\n",
       "       [0.9623698 , 0.03763014],\n",
       "       [0.09353005, 0.90646994],\n",
       "       [0.7499829 , 0.25001708],\n",
       "       [0.07680145, 0.9231986 ],\n",
       "       [0.9628954 , 0.03710455],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9637345 , 0.0362655 ],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9627647 , 0.03723529],\n",
       "       [0.17982039, 0.8201796 ],\n",
       "       [0.9443925 , 0.05560752],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.96263355, 0.03736646],\n",
       "       [0.02010713, 0.97989285],\n",
       "       [0.9597781 , 0.04022191],\n",
       "       [0.3565513 , 0.64344865],\n",
       "       [0.9520757 , 0.04792422],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.96302575, 0.03697426],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9634783 , 0.03652171],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.7989912 , 0.20100878],\n",
       "       [0.15021567, 0.8497844 ],\n",
       "       [0.5631801 , 0.43681994],\n",
       "       [0.03059999, 0.9694    ],\n",
       "       [0.7989912 , 0.20100878],\n",
       "       [0.04178001, 0.95822006],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.06285739, 0.9371426 ],\n",
       "       [0.90056133, 0.09943865],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9635425 , 0.0364575 ],\n",
       "       [0.01183563, 0.9881643 ],\n",
       "       [0.9484512 , 0.05154875],\n",
       "       [0.16448376, 0.8355162 ],\n",
       "       [0.9629606 , 0.03703936],\n",
       "       [0.02756247, 0.97243756],\n",
       "       [0.9623037 , 0.03769634],\n",
       "       [0.103067  , 0.896933  ],\n",
       "       [0.9547874 , 0.04521263],\n",
       "       [0.01627501, 0.983725  ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404761904761905"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(rounded_predictions , test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix to visually see how the model is predicting on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , plot_confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[195,  15],\n",
       "       [ 10, 200]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working need to fix this\n",
    "# cm_labels = ['no side effects', 'has side effects']\n",
    "# plot_confusion_matrix(cm, cm_labels, title= 'CM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/medical_trial.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The save functions saves the :\n",
    "- Architecture of the model\n",
    "- The weights the model\n",
    "- The training config like loss, optimizer\n",
    "- The state of the optimizer, allowing to resume exactly where we left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(\"../models/medical_trial.h5\") # The same architecture like old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 1),\n",
       "    'dtype': 'float32',\n",
       "    'units': 16,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 32,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 2,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}],\n",
       " 'build_input_shape': TensorShape([None, 1])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we only want to save the model architecure but not weights and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string =  model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"build_input_shape\": [null, 1]}, \"keras_version\": \"2.3.0-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save only weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"../models/medical_trial_only_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the weights\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(16, input_shape = (1,), activation = 'relu'),\n",
    "    Dense(32, activation= 'relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(\"../models/medical_trial_only_weights.h5\") # passing previously saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_3_1/kernel:0' shape=(1, 16) dtype=float32, numpy=\n",
       " array([[-0.0881601 ,  0.01425132, -0.5924668 , -0.03857851, -0.01336461,\n",
       "         -0.4658573 , -0.338716  ,  0.7087602 ,  0.5610516 ,  0.7992864 ,\n",
       "         -0.04569886, -0.09786454, -0.24511063,  0.24557899, -0.30598316,\n",
       "          0.5789852 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3_1/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([ 0.        , -0.03150105,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.25418225, -0.2268508 , -0.2855868 ,\n",
       "         0.26869792,  0.        ,  0.        , -0.11582717,  0.        ,\n",
       "        -0.2843283 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_4_1/kernel:0' shape=(16, 32) dtype=float32, numpy=\n",
       " array([[ 1.76257640e-01, -3.43990088e-01,  7.78893232e-02,\n",
       "         -2.07280129e-01,  2.80376971e-02, -1.23713613e-02,\n",
       "          5.74733019e-02, -2.63981313e-01, -9.16838944e-02,\n",
       "         -9.94279683e-02,  3.13315302e-01, -2.16032013e-01,\n",
       "          1.18676335e-01,  1.20654702e-02, -3.32724929e-01,\n",
       "         -3.18656385e-01, -1.00840896e-01,  2.21887231e-03,\n",
       "          1.10945851e-01, -2.25616544e-01,  1.73413008e-01,\n",
       "         -1.53413340e-01, -2.22937524e-01,  4.05299962e-02,\n",
       "          3.04795235e-01, -4.59556580e-02, -5.57654202e-02,\n",
       "         -4.68550622e-02, -7.20968246e-02, -3.05302233e-01,\n",
       "          2.51199335e-01, -1.55108318e-01],\n",
       "        [ 2.06047818e-01, -2.39492655e-01, -1.50664300e-01,\n",
       "          2.16155332e-02,  1.55010551e-01,  1.45719290e-01,\n",
       "         -3.12722862e-01, -2.81092823e-01, -1.55813888e-01,\n",
       "          3.39874268e-01, -1.06792554e-01,  1.49583310e-01,\n",
       "         -2.43123565e-02,  2.74827212e-01,  1.15573190e-01,\n",
       "          2.00341076e-01,  2.64405966e-01, -1.56618357e-01,\n",
       "          1.87317997e-01,  1.52671084e-01, -1.40732199e-01,\n",
       "         -3.50666910e-01, -1.58962488e-01, -1.46596268e-01,\n",
       "          9.72918235e-04,  6.75081313e-02,  9.05404687e-02,\n",
       "          2.68539429e-01,  1.07315980e-01, -3.44679624e-01,\n",
       "         -1.04349434e-01, -2.33699381e-01],\n",
       "        [ 1.88548297e-01, -1.22486666e-01,  3.59619558e-02,\n",
       "         -6.77264333e-02, -3.22891891e-01,  1.95478767e-01,\n",
       "          9.26470757e-03,  2.57836968e-01,  3.01028699e-01,\n",
       "         -8.17430615e-02, -1.61334932e-01,  1.04095042e-01,\n",
       "         -2.28652626e-01, -2.29098469e-01, -1.45410329e-01,\n",
       "          2.62981385e-01,  3.00130159e-01, -1.15619510e-01,\n",
       "         -1.96959645e-01, -2.15377212e-02, -2.69324183e-01,\n",
       "         -2.72051990e-02, -6.50273561e-02,  3.79678309e-02,\n",
       "          8.26473534e-02, -3.19914818e-01, -1.22110635e-01,\n",
       "          4.25139368e-02, -3.50721449e-01, -6.64568245e-02,\n",
       "          2.24772424e-01,  2.27198511e-01],\n",
       "        [-3.09192806e-01,  1.09236240e-02, -4.52459157e-02,\n",
       "         -5.25134504e-02, -1.65715337e-01,  6.00427389e-02,\n",
       "          1.62013918e-01,  6.84660375e-02,  3.49377096e-02,\n",
       "          5.49288094e-02,  1.13651931e-01,  1.16431504e-01,\n",
       "          2.85548121e-01,  7.05659688e-02, -3.14091891e-01,\n",
       "          1.74158186e-01,  1.53203279e-01, -5.19259274e-02,\n",
       "         -2.78627753e-01,  6.95232451e-02,  1.28413528e-01,\n",
       "         -3.12809944e-01,  1.29515082e-01,  1.54000223e-02,\n",
       "         -9.30882990e-02, -2.81059116e-01,  1.24970287e-01,\n",
       "         -1.74738392e-01,  3.06643099e-01,  3.21634978e-01,\n",
       "         -9.98478234e-02,  1.11260414e-01],\n",
       "        [-7.65305758e-02, -3.62741947e-02,  2.23858684e-01,\n",
       "         -1.97461694e-01,  8.68293643e-03,  1.55351609e-01,\n",
       "         -3.25668931e-01,  8.18391442e-02, -2.42577612e-01,\n",
       "         -2.51438916e-02,  2.11435050e-01,  2.60462463e-02,\n",
       "          8.34736228e-03, -2.88573384e-01, -2.03928530e-01,\n",
       "         -2.61422753e-01, -1.94879189e-01,  2.41222948e-01,\n",
       "          9.01171267e-02, -5.67762852e-02, -2.62844354e-01,\n",
       "          1.73827678e-01, -1.78164244e-03, -3.03346872e-01,\n",
       "         -3.31222713e-01, -2.67444253e-01, -2.05393225e-01,\n",
       "          5.94565272e-03, -1.27366334e-01,  2.63447076e-01,\n",
       "          3.95378470e-03,  1.71501338e-02],\n",
       "        [ 3.29494774e-02,  1.13672823e-01, -3.06450754e-01,\n",
       "          8.70681405e-02,  8.74665082e-02,  6.77847862e-02,\n",
       "          4.45419550e-02,  3.73422801e-02,  2.05422312e-01,\n",
       "          1.31177008e-02, -1.03015244e-01,  3.01581711e-01,\n",
       "         -1.19557455e-01,  5.77169955e-02, -1.26904249e-03,\n",
       "          2.12797314e-01, -2.54628420e-01,  7.29728937e-02,\n",
       "          9.90477204e-03, -4.33813334e-02,  3.28640312e-01,\n",
       "          4.45020199e-02, -1.91392377e-01, -2.13116407e-02,\n",
       "         -2.82714665e-01,  4.91100848e-02, -3.46970797e-01,\n",
       "         -1.05932653e-01, -2.73499757e-01, -1.78461224e-01,\n",
       "          1.02101326e-01,  1.12671494e-01],\n",
       "        [-2.90541232e-01, -2.55387545e-01,  1.43190980e-01,\n",
       "          2.14488238e-01, -1.32857069e-01,  3.27226609e-01,\n",
       "          2.65934795e-01, -1.81646168e-01,  2.29631692e-01,\n",
       "          1.53831273e-01, -5.79431355e-02, -2.28082642e-01,\n",
       "          1.04245752e-01,  6.39415681e-02, -2.90889114e-01,\n",
       "         -2.71083385e-01,  2.99462676e-02,  1.31143034e-01,\n",
       "          4.16040719e-02, -3.43721777e-01,  2.32504576e-01,\n",
       "          1.01938993e-01,  3.35359663e-01,  2.20967084e-01,\n",
       "          2.35299081e-01,  1.17772192e-01,  1.95983261e-01,\n",
       "          4.57124710e-02,  1.85993046e-01,  6.92707002e-02,\n",
       "          1.69770271e-01, -6.49879873e-02],\n",
       "        [-7.25737959e-02,  2.21594900e-01,  4.84822333e-01,\n",
       "         -8.34242627e-03, -8.81987214e-01, -3.31758171e-01,\n",
       "          1.42928004e-01, -4.61478859e-01, -3.58982801e-01,\n",
       "          6.57175660e-01, -6.17168918e-02, -4.85315314e-03,\n",
       "          4.73527342e-01,  5.84767759e-01,  1.72953621e-01,\n",
       "          2.59283513e-01, -2.31891498e-03, -6.74365878e-01,\n",
       "          2.59710908e-01,  3.89617264e-01, -5.44052958e-01,\n",
       "          9.59460810e-02, -2.44468361e-01, -3.27679515e-01,\n",
       "         -3.88523728e-01, -1.84895352e-01, -2.66443759e-01,\n",
       "         -5.92599452e-01,  3.94951969e-01, -4.33266610e-02,\n",
       "         -3.43232334e-01,  4.77504224e-01],\n",
       "        [-3.70783925e-01,  1.82982445e-01,  6.53069675e-01,\n",
       "         -1.45967752e-01, -8.66962790e-01,  2.58523729e-02,\n",
       "          5.41889250e-01, -4.82722908e-01,  2.53498167e-01,\n",
       "          2.57319570e-01,  5.79357266e-01,  2.38342851e-01,\n",
       "          6.33075655e-01, -7.80301690e-02,  3.11737746e-01,\n",
       "         -8.72629285e-02, -3.09664875e-01, -6.01414502e-01,\n",
       "          4.49880034e-01,  6.44492865e-01, -5.80991447e-01,\n",
       "          3.22024822e-02,  5.08988202e-02, -2.82949239e-01,\n",
       "         -1.14477344e-01,  3.51815253e-01, -5.39788723e-01,\n",
       "         -2.13358074e-01,  4.13392872e-01, -1.39464751e-01,\n",
       "         -1.56060457e-02,  3.67269933e-01],\n",
       "        [ 2.14302212e-01, -2.57192165e-01,  2.70360678e-01,\n",
       "         -2.43655786e-01, -5.41618109e-01,  2.65908301e-01,\n",
       "          6.05841815e-01, -6.30873442e-01,  2.38192320e-01,\n",
       "          4.54747289e-01,  6.19435072e-01, -2.47729301e-01,\n",
       "          2.86290914e-01,  5.87881148e-01,  3.36234331e-01,\n",
       "         -2.89094418e-01,  1.09226309e-01, -1.77522361e-01,\n",
       "          3.16270709e-01,  4.11261916e-01, -1.33539379e-01,\n",
       "         -1.45447254e-01,  8.74940753e-02, -1.50047496e-01,\n",
       "         -6.28808677e-01, -1.01899207e-02, -7.51183152e-01,\n",
       "         -2.84630865e-01,  4.08453107e-01, -1.81029856e-01,\n",
       "         -2.48070538e-01,  4.48257744e-01],\n",
       "        [-1.72866836e-01, -1.23433871e-02, -4.15706895e-02,\n",
       "         -2.10663676e-03,  3.96225959e-01, -1.03309844e-02,\n",
       "         -2.31271416e-01,  4.79298413e-01, -2.26459101e-01,\n",
       "          2.65997231e-01,  3.05566162e-01, -3.05598795e-01,\n",
       "         -2.86663651e-01,  6.97211847e-02,  2.99701452e-01,\n",
       "         -1.09311424e-01,  5.00983149e-02,  4.64449495e-01,\n",
       "         -1.34794414e-01, -2.14511797e-01,  3.33410174e-01,\n",
       "         -8.86237174e-02,  9.06968396e-03, -6.19466007e-02,\n",
       "          3.52016211e-01, -8.18398297e-02,  4.41622257e-01,\n",
       "          4.40207392e-01,  4.73308824e-02,  2.57493466e-01,\n",
       "          7.99346119e-02, -1.41634122e-01],\n",
       "        [-2.47284412e-01,  2.26030439e-01,  1.40706986e-01,\n",
       "          1.54444605e-01,  1.89687908e-02, -3.47106338e-01,\n",
       "         -3.01365793e-01,  1.11455619e-02,  5.13716936e-02,\n",
       "         -9.34621394e-02, -1.72805190e-01,  2.75309116e-01,\n",
       "         -2.01266617e-01, -6.25809133e-02, -1.46523938e-01,\n",
       "         -3.18094730e-01, -1.20255992e-01,  1.96881503e-01,\n",
       "         -2.77852237e-01, -1.41738415e-01, -2.04087093e-01,\n",
       "          2.64833957e-01,  1.80273056e-02, -5.21654785e-02,\n",
       "         -1.84107542e-01, -1.12861395e-03,  1.79182857e-01,\n",
       "          3.18377346e-01, -2.05305889e-01, -3.26622307e-01,\n",
       "         -7.16278851e-02,  2.10442156e-01],\n",
       "        [ 8.00386369e-02, -2.51083195e-01,  3.50938588e-01,\n",
       "         -2.19026297e-01,  7.30682909e-02,  2.21667975e-01,\n",
       "         -5.91402948e-02,  1.77296370e-01,  2.05029339e-01,\n",
       "          2.81977922e-01, -1.69864520e-01,  1.84573859e-01,\n",
       "         -3.00116003e-01, -1.07743606e-01, -2.60342777e-01,\n",
       "         -3.14222872e-01, -3.18326384e-01,  1.28757060e-02,\n",
       "          1.04322970e-01,  1.87539965e-01,  1.58837885e-01,\n",
       "         -1.38097942e-01,  8.16631317e-02,  1.79178327e-01,\n",
       "         -2.90527076e-01, -1.73135117e-01,  3.61418426e-02,\n",
       "          3.87844443e-03,  1.47268087e-01,  1.58970386e-01,\n",
       "         -1.05023876e-01, -2.14402273e-01],\n",
       "        [ 1.61107093e-01,  1.34059578e-01,  7.20514953e-02,\n",
       "         -1.84012756e-01, -1.09690487e-01,  5.07477149e-02,\n",
       "          4.61721718e-02, -1.11032438e+00, -3.23092610e-01,\n",
       "         -3.19688320e-02,  3.21404971e-02, -2.90643990e-01,\n",
       "         -1.11569948e-01, -6.90659955e-02, -6.47883415e-02,\n",
       "         -1.04842395e-01,  4.78230715e-02, -7.81280816e-01,\n",
       "          4.97726910e-03,  4.26244766e-01, -9.40719724e-01,\n",
       "         -1.80515707e-01, -3.13266307e-01,  3.15034986e-02,\n",
       "         -5.32667637e-01,  1.86816603e-01, -7.22162902e-01,\n",
       "         -1.02985215e+00, -1.47653416e-01, -6.16217971e-01,\n",
       "         -6.50933087e-02,  2.49918737e-02],\n",
       "        [ 2.24124104e-01, -1.59492612e-01, -1.42779619e-01,\n",
       "          2.99517423e-01, -1.43920481e-02,  1.38113111e-01,\n",
       "         -3.23709458e-01, -3.28344256e-01, -2.57856846e-01,\n",
       "         -3.37048590e-01, -6.91152811e-02, -1.46944731e-01,\n",
       "         -1.40458673e-01,  1.69201404e-01,  1.65505558e-01,\n",
       "         -1.21546030e-01, -3.71456146e-03,  3.28130990e-01,\n",
       "         -2.68242776e-01,  8.17148089e-02, -2.26333216e-01,\n",
       "         -2.97453105e-02,  2.58487016e-01, -1.33261502e-01,\n",
       "         -2.01526418e-01,  8.74048769e-02, -1.34448439e-01,\n",
       "          3.11269969e-01, -2.53366202e-01, -1.20749027e-01,\n",
       "         -2.04777539e-01, -2.73103744e-01],\n",
       "        [ 2.26084515e-01, -1.00343227e-01,  5.44456661e-01,\n",
       "         -4.07864451e-02, -4.37539190e-01,  1.48971930e-01,\n",
       "          1.64303690e-01, -5.01635253e-01,  6.40758425e-02,\n",
       "          7.05434859e-01,  2.92447388e-01, -1.06279761e-01,\n",
       "          5.33131123e-01,  2.18127035e-02,  3.69123995e-01,\n",
       "         -1.43190116e-01,  1.26312390e-01, -9.67127740e-01,\n",
       "          5.26327431e-01,  6.15422249e-01, -9.23759818e-01,\n",
       "         -1.65728480e-01, -8.30520391e-02,  3.24085146e-01,\n",
       "         -8.43088210e-01, -3.06855261e-01, -6.62526667e-01,\n",
       "         -4.81208771e-01,  3.17327231e-01, -7.48831689e-01,\n",
       "          3.20930988e-01, -1.51602840e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_4_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.03944143, -0.02354841, -0.09212179,  0.08416715,  0.10917756,\n",
       "        -0.05225626, -0.03983345,  0.27784273, -0.01354447, -0.18423998,\n",
       "        -0.15544356, -0.00531526, -0.03115764, -0.12211274, -0.13290164,\n",
       "        -0.00765252, -0.02519118,  0.26701736, -0.0388306 , -0.05625171,\n",
       "         0.2565924 , -0.00511237, -0.00978172,  0.        ,  0.25080505,\n",
       "         0.        ,  0.28468218,  0.18568379, -0.10565497,  0.08831926,\n",
       "        -0.03029495, -0.06869356], dtype=float32)>,\n",
       " <tf.Variable 'dense_5/kernel:0' shape=(32, 2) dtype=float32, numpy=\n",
       " array([[ 0.21854316, -0.10601555],\n",
       "        [ 0.02817424, -0.3901584 ],\n",
       "        [ 0.00281742,  0.7229936 ],\n",
       "        [ 0.32741222, -0.1864305 ],\n",
       "        [-0.6716506 ,  0.52819186],\n",
       "        [ 0.2034754 , -0.35639563],\n",
       "        [-0.7234095 ,  0.31650382],\n",
       "        [ 0.61530346, -0.80216825],\n",
       "        [ 0.04810579, -0.10300619],\n",
       "        [-0.40971056,  0.13427223],\n",
       "        [-0.53204185,  0.18917115],\n",
       "        [-0.41008887,  0.01728736],\n",
       "        [-0.02617861,  0.6271213 ],\n",
       "        [-0.58111656,  0.34609982],\n",
       "        [-0.4563159 ,  0.525039  ],\n",
       "        [-0.24209951,  0.09533819],\n",
       "        [-0.136395  , -0.14053078],\n",
       "        [ 1.0519032 , -0.3924498 ],\n",
       "        [-0.19145375,  0.2552057 ],\n",
       "        [-0.32558313,  0.37458652],\n",
       "        [ 0.64245445, -1.0633543 ],\n",
       "        [-0.02920003,  0.35910198],\n",
       "        [ 0.07113741,  0.11397512],\n",
       "        [-0.26438758,  0.2044951 ],\n",
       "        [ 0.66951627, -0.90271133],\n",
       "        [-0.28860545,  0.22881612],\n",
       "        [ 0.47871736, -0.91662294],\n",
       "        [ 0.529398  , -0.8944937 ],\n",
       "        [-0.6939407 ,  0.45154628],\n",
       "        [ 0.21206628, -0.7130201 ],\n",
       "        [-0.13188584,  0.26573193],\n",
       "        [-0.71017164,  0.51615113]], dtype=float32)>,\n",
       " <tf.Variable 'dense_5/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.04018797, -0.04018803], dtype=float32)>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlcondab0e91abca1e444e6ba4cae782abe292d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
