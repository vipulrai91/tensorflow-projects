{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Notes from [DeepLizard](https://deeplizard.com/learn/playlist/PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense Layer - connects input to each output layers      \n",
    "Here 32 is hidden layer , first layer is specified by shape which has 10 neurons        \n",
    "Even though we have specified 2 layers but this is a 3 layer model since we have specified input_shape which\n",
    "becomes the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32,input_shape = (10,), activation='relu'), # 32 - no of neurons , input_shape - input data\n",
    "    Dense(2 , activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are different types of layers:\n",
    " - Dense (fully connected)\n",
    "  - Connects each input to each output layer\n",
    " - Convolutional Layers \n",
    "  - Image Analysis\n",
    " - Pooling Layers\n",
    " - Recurrent Layers\n",
    "  - Time Series\n",
    " - Normalization Layers\n",
    " - Many others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another model to classify cats and dogs with 3 input features , note first layer in list is hidden\n",
    "# and is actually second layer \n",
    "\n",
    "layers = [\n",
    "    Dense(5, input_shape = (3,),  activation='relu'),   # we need to provide only the first layer shape\n",
    "    Dense(2 , activation='softmax') # model will be able to infer the next layers\n",
    "]\n",
    "\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way of specifying activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5 , input_shape = (3,)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer updates the weights in the model , eg : SGD  \n",
    "The main function of optmizer is to minimize the loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens during one pass ?\n",
    "\n",
    "During first pass the weights are initialized at random  and passes through network , at the last layer a probability \n",
    "is spit out , the porbability is compared to actual value , difference  is called loss , and this gets optmized using optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epcoh - Single pass through the data is called epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.metrics import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dense(16, input_shape = (1,) , activation='relu'),\n",
    "    Dense(32 , activation= 'relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=.001) , loss= 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_samples, y=train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sparse_categorical_crossentropy'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7f815100fa50>,\n",
       " <keras.layers.core.Dense at 0x7f815100fd50>,\n",
       " <keras.layers.core.Dense at 0x7f815100fe10>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we want to use the train data and take out validation from that we can use validation_split which will take the given percent as  validaiton data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_samples, y=train_labels,validation_split=0.3, batch_size=10, epochs=20, shuffle=True, verbose=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Else if we have seperate validation data , we can pass that using validate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_set = [(sample , label)......(sample,label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_sample, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to know if the model is overfitting\n",
    "#### If the validation loss is more than training loss , the model is probably overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to reduce overfitting\n",
    " - #### We can do Data Augmentation\n",
    "     - Cropping\n",
    "     - Rotating\n",
    "     - Zooming\n",
    "     - Flipping\n",
    "     - etc\n",
    " - #### Dropout\n",
    "     - Randomly ignores the node from the layers, hence the name dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting \n",
    "#### Not able to classify the data it was even trained on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to reduce underfitting\n",
    " - #### Increase the model complexity. adding more layers or more neurons - opposite to overfitting\n",
    " - #### Add more features to input sample\n",
    " - #### Reduce dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy - we do not measure accuracy since we do not know the labels. Clustering is one example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder \n",
    "a nn which takes in input ans outputs a reconstruction of this input . The loss function here is measuring how similar the reconstructed image is compared to original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow - Image -> Encoder -> Compressed Representation -> Decoder -> Reconstructed Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss = Reconstructed / Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer is still some version of SGD.  Practical Application is removing noise form the similar image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi - Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses a combination of both supervised and unsupervised learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo Labeling - labeling some portion of the data, whereas other portions remain unlabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps - First train the labeled data using regular nn , then predict the unlabeled data using this model , then again train the model on combination of (labeled +  pseudo - labeled data(the one we predicted) and run through the full model again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to create new data based on modification to existing data, to add more data to create more samples\n",
    "Eg : if most of the images of dogs are facing towards right then it is difficult to learn the left facing dogs\n",
    "We do this by horizontally flipping the images , vertically we don't do it and it wont make sense because in real world we rarely will have vertical images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector length will be equal  to number of classes / labels.  \n",
    "Each element of the vector will be zero , except the one which the vector corresponds to (hence the name one hot encode)\n",
    "Eg :\n",
    "\n",
    "cat - [1,0,0]    \n",
    "dog - [1,0,1]      \n",
    "lizard - [0,0,1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A type of nn which is specialized in pattern detection. Hence useful for image analysis.  \n",
    "Basis of CNN is convolutions ie hidden layers , they can have other layers as well.\n",
    "At each layer we need to specify the **filter** we want to detect.\n",
    "\n",
    "Eg : Edge detector filter detects the edges      \n",
    "As the layer progresses , the ending layers would be able to detect more features like ears , eyes , mouth etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A filter is a matrix of some size Eg (3,3) , (4,4) , this matrix slides through the whole image one by one thereby visiting all the pixels in the image , this process is called **convolve**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when adding a convolutional layer to a model, we also have to specify how many filters we want the layer to have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient ascent differs from gradient descent by trying to maximize the  loss in order to emphasize pattern detection of the filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply filter to orignal image in cnn layer , the resulting output shrinks , or becomes smaller   \n",
    "this happens because the filter cannot slide to some of the pixels over the edges so the output becomes smaller\n",
    "\n",
    "Eg for 4 by 4 input and 3 by 3 filter the output is only 2 by 2 matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be calculate ahead of time using the forumla\n",
    "$ (n-f +1)*(n-f+1) $    \n",
    "where n = image row/column. \n",
    "      f = filter column/row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation for above example 2*2 here\n",
    "(4-3+1)* (4-3+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example. for 28*28 image with 3*3 filter output will be 26*26\n",
    "(28 -3+1)* (28-3+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(676)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass through many layers and many filter the image will tend to become smaller and smaller    \n",
    "Another issue is we are losing valueable information at the edges and throwing away that info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero padding comes into play where we can preserve the image as original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While specifying filter we can specify whether to use padding or not   \n",
    "Depending upon the input it could be one border or two or 3 and so on   \n",
    "Most nn can automatically add padding we just need to specify if we want padding or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter size is specified by *kernel_size* parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are two types of padding ,  default is valid padding\n",
    "- valid - means no padding\n",
    "- same - means padding needs to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling in NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling is done after applying the filter in the network.   \n",
    "Filter size $2 * 2$     \n",
    "Stride = 2\n",
    "\n",
    "We calculate the max values of the $2*2$ matrix and then move by the number of strides,whcih is 2 here\n",
    "\n",
    "We can think this $2*2$ as pools and since we are taking max , hence the name max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an example\n",
    "\n",
    "\n",
    "A $28*28$ matrix after applying filter -> $26*26$ -> after max pooling becomes $13*13$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we need max pooling ?\n",
    "- Since the network will look only larger values(more prominent features), it will be able to learn more and since size decreases it will decrease the computational load\n",
    "- Reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D #since the previous layers were 2d we are using maxpool2d\n",
    "from keras.layers import Conv2D ,Flatten\n",
    "\n",
    "layers = [\n",
    "    Dense(16 , activation='relu', input_shape = (20,20,3)),\n",
    "    Conv2D(32, kernel_size = (3,3) ,activation= 'relu' , padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2) ,strides= 2, padding='valid'),\n",
    "    Conv2D(64, kernel_size=(5,5) ,activation='relu', padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(2,activation='softmax')\n",
    "]\n",
    "\n",
    "model=Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7f81334f2dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f81334f2250>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f81335ff7d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f81335ffd90>,\n",
       " <keras.layers.core.Flatten at 0x7f81334cc210>,\n",
       " <keras.layers.core.Dense at 0x7f81334ccad0>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pooling - takes the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlcondab0e91abca1e444e6ba4cae782abe292d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
